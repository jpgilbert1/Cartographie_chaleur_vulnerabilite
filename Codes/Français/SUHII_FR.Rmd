---
title: "SUHII"
author: "Departement de géographie - Université Laval"
date: "13/07/2021"
output: html_document
---

```{r eval =FALSE}
library(raster)
library(rgdal)
library(sf)
library(mgcv)
```

#Calcul des SUHII avec le modèle GAM. 
Pour ce faire, le code prends les fichiers d'imperméabilité, de température du sol, du NDVI et du NDBI fait la jointure spatiale entre les données. Le code découpe chaque image pour chaque RMR pour chaque province. Les images d'imperméabilité, de NDVI et de NDBI sont préalablement découpées avec les fichiers de RMR dans ArcGIS Pro.

La deuxième boucle s'assure qu'il y a une justaposition d'une image de température du sol pour une RMR. Si justiaposition il y a, le code combine l'image de température du sol, d'imperméabilité du sol, de NDVI et de NDBI ensemble. L'image combinée est vérifiée pour s'assurer que l'image n'est pas vide. 

Par la suite, le modèle GAM est appliqué. L'image combiné est transformée en matrice pour pouvoir appliqué adéquatement le modèle GAM. On fait la moyenne des valeurs de température du sol, de NDVI et de NDBI par niveau d'imperméabilité du sol (donc une moyenne pour 1,2,3, ..., 100).

Souvent, il y a plusieurs images de température du sol pour une année et une RMR pour donc je garde que le modèle qui fit le mieux pour modélise les données. Donc, haut dans la boucle, j'ai mis une variable nommée r_carré que j'ai mis à 0. Puis, si le R2 est plus haut que 0, le code fait la prédiction pour cette image de température du sol. Donc, cela assure que le SUHII est le meilleur pour cette RMR pour l'année regardée. 

En termes de prédiction, le meilleur modèle est pris et les prédictions sont faites à l'aide des données d'imperméabilité du NDVI et du NDBI. Une fois la prédiction faite, le tout est mis dans une matrice et est reclassifié à l'aide du fichier raster d'imperméabilité du sol en remplaçant les valeurs d'imperméabilité par la valeur du SUHII. Le code s'assure que le raster est découpé comme il faut avec le shp, puis il exporte le fichier raster.
 
```{r eval = FALSE}

raster_isa <- raster("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\Impermeabilite_des_sols\\QC\\prov_QC_reclass_100_2.tif")
NDVI <- raster("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\NDVI\\QC_2018\\NDVI_2018.tif")
NDBI <- raster("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\NDBI\\QC_2018\\NDBI_2018.tif")
shp <- readOGR("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\Shp_file\\RMR\\RMR_2021\\QC.shp")

filelist <- list.files("D:\\tempo\\Landsat_methode_Wang\\QC_2017\\cut_3", pattern = ".tif", full.names = TRUE)
filelist_court <- list.files("D:\\tempo\\Landsat_methode_Wang\\QC_2017\\cut_3", pattern = ".tif")
shp_RMR <- spTransform(shp,
                       crs(raster_isa))
rm(shp)

for(ii in 1:nrow(shp_RMR))
{

  rr55 <-crop(raster_isa,extent(shp_RMR[ii,] ))
  rr5 <- mask(rr55, shp_RMR[ii,] )
  rm(rr55)
  rr5[rr5 < 0 ] <- NA
  rr5[rr5 > 100 ] <- NA
  rr5 <- round(rr5)
  r_carre <- 0
  for(i in  1:length(filelist))
  {
    print(i)
    tryCatch({
        lst <- raster(filelist[i])
        if(lst@data@max > 2100000000)
        {
          lst = lst/100
          lst[lst == 0] <- NA
        }
        
        rr_lst <-crop(lst,extent(shp_RMR[ii,] ))
        rr_lst <- mask(rr_lst, shp_RMR[ii,] )
        ex <- extent(rr5)
        rr_lst <- crop(rr_lst, ex)
        rm(lst, ex)
       
            
    #if(rr_lst@data@min == Inf && rr_lst@data@max == -Inf)
    #{
     # print("pas bon")
    #}
      #else{
        
     
        
      isa <- crop(rr5, extent(rr_lst))
      r1 <- resample(isa, rr_lst)
      
      isa <- raster(vals=values(r1),ext=extent(rr_lst),crs=crs(rr_lst),
                        nrows=dim(rr_lst)[1],ncols=dim(rr_lst)[2])
      
      
      rr_NDVI <- crop(NDVI, extent(rr_lst))

      
      rr_NDVI <- raster(vals=values(rr_NDVI),ext=extent(rr_lst),crs=crs(rr_lst),
                        nrows=dim(rr_lst)[1],ncols=dim(rr_lst)[2])
      
      
      
      rr_NDBI <- crop(NDBI, extent(rr_lst))
      
      rr_NDBI <- raster(vals=values(rr_NDBI),ext=extent(rr_lst),crs=crs(rr_lst),
                        nrows=dim(rr_lst)[1],ncols=dim(rr_lst)[2])
      
      rr3 <- stack(isa,rr_NDVI, rr_NDBI, rr_lst)
      
      rm(isa, rr_NDVI, rr_NDBI)
      v <- data.frame(na.omit(values(rr3)))
      names(v) <- c('ISA',  'NDVI', 'NDBI','Mean_LST')
      if(nrow(v) != 0)
      {
          v$ISA <- round(v$ISA)
          mean_lst <- aggregate(v, list(v$ISA), mean)
          if(nrow(mean_lst) > 4)
          {
          g <- gam(Mean_LST ~ s(ISA) +NDVI+NDBI,data=mean_lst)
          if(summary(g)$r.sq > r_carre)
          {
            r_carre <- summary(g)$r.sq
            print(summary(g)$r.sq)
            
            #prediction
            
            test <- predict(g, mean_lst)
            test <- data.frame(test)
            test$SUHII <- NA
            test <- cbind(mean_lst, test)
  
            for(hh in 1:nrow(data.frame(test)))
            {
             if(hh == 1)
              {
                test$SUHII[hh] <- 0
              }else
              {
                test$SUHII[hh] <- test$test[hh] - test$test[hh-1] +  test$SUHII[hh-1]
              }
            }
            rclmat <- matrix(test[,c(2,7)], ncol=2 )
            t <- as.matrix(test[,c(2,7)])
  
            test_2 <- raster::reclassify(rr5,t)
    
            #shp <- st_read(folder_shp2[i])
            #rr <-crop(test_2,extent(shp[ii,]))
            #rr4 <- mask(rr, shp[ii,] )
            test_2 [test_2 < 0 ] <- NA
            test_2 [test_2  > 50] <- NA
            plot(test_2 )
            nom_fichier_raster <- paste0("D:\\tempo\\Landsat_methode_Wang\\QC_2018\\SUHII2_",shp_RMR@data$RMRIDU[ii]) 
            nom_fichier_raster <- paste0(nom_fichier_raster,"_") 
            nom_fichier_raster <- paste0(nom_fichier_raster, filelist_court[i] )
  
            
            writeRaster(test_2 , nom_fichier_raster, 'GTiff', overwrite=TRUE)
            
            
             #nom_fichier <- paste0("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\SUHII\\Gam_final\\R2_2019\\SUHII_", shp_RMR@data$RMRIDU[ii])
             
             # nom_fichier <- paste0(nom_fichier, ".txt")
              
             # write.table(r_carre , file = nom_fichier, sep = "\t",
             # row.names = TRUE, col.names = NA)
             
          }
        }
      }
    #}
      }, error=function(e){})
  } 
}
```

Finalement, il faut prendre le meilleur modèle. Cette section de code fait cela. D'abord, il faut lire le fichier R2. Celui-ci est fait à la main, en prenant les fichiers texte et en mettant la valeur du R2 pour chaque RMR et chaque année. Comme j'ai pas écrit le nom de la ville de la même manière donc je me suis fait une variable avec les nom des villes des raster et je cbind avec le fichier de r2.

Renomme les colonnes de R2. Les Na sont mis à 0. pmax permet d'avoir la valeurs maximal pour chaque ligne et la stock dans la colonne max. Ainsi, l'année qui est == a max dit que c,est le meilleur modele a prendre.  Je lis ensuite le fichier AD pour le Canada. 

Et on fait une boucle qui commence par bouclier sur les lignes. Pour les lignes, va me chercher le fichier rmr. Puis, ne garde que les polygone d'AD qui égale le RMRPIDU de la RMR. Pour une raison que je comprends pas, le == ne marche pas avec les nombres car en facteurs (levels) mais avec as.character, ça fonctionne.

Ensuite on loop sur les colone, et on vérifie si la valeur de la colonne j est la valeur max. Lorsque c'est le cas, importe le raster correspondant, ensuite transforme le raster en point, ensuite transforme le fichier AD en SpatialPolygon pour pouvoir faire la jointure. Transform la projection des points pour fitter avec AD. Ensuite, la fonction over est le spatial joint. Mais ca fait juste un dataframe pour chacune des AD et la moyenne des valeurs grid. Donc on doit cbind les deux dataframes. D'abord combine le nom des ad pour avoir une clé de merge pour le merge. Finalement, exporte le fichier en shp. pour pouvoir faire l'ACP. 

```{r eval = FALSE}
library(ggplot2)

r2 <- read.table("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\SUHII\\Gam_final\\R2_gam_2018_2020.csv", sep =";", header = TRUE)

#nom_fichier_raster <- c("Alma","Baie_comeau","Campelton","Cowan","Dolbeau","Drummond","Gatineau","Granby","Hawk","Joliette","Lachute","Matane","MTL","QC","RDL","Rimouski","Rouyn","Sag","Saint_hyacinthe","Sainte_George","Sainte_Marie","Salab","Sept_iles","Shawi","Sherby","Sorel","Thetford","TR","Valdor","Victo")

r2$X <- as.character(r2$X)
r2$X[1] <-"001" 
r2$X[2] <-"010"
r2$X[3] <-"011"
r2$X[4] <-"015" 
r2$X_char <- r2$X
r2$X <- paste("SUHII_", r2$X, sep="") 
  


names(r2)[names(r2) == "X2018"] <- "2018"
names(r2)[names(r2) == "X2019"] <- "2019"
names(r2)[names(r2) == "X2020"] <- "2020"

r2[is.na(r2)] <- 0
r2$Max <- pmax(r2$`2018`,r2$`2019`,r2$`2020`)
AD_shp <- sf::st_read(
"D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\Shp_file\\AD\\lad_000b21a_f\\AB\\AD_RMR_SpatialJoin.shp") 

 for (i in 145:146)#:nrow(r2))
{
  #rmr_file_path <- "D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\Shp_file\\RMR\\31923\\rmr_decoup\\" 
  #rmr_file_path <- paste0(rmr_file_path, r2$X[i])
  #rmr_file_path <- paste0(rmr_file_path, ".shp")
  #rmr_shp <- sf::st_read(rmr_file_path)
 # AD_rmr_shp <- AD_shp[which(as.character(AD_shp$RMRPIDU) == as.character(rmr_shp$RMRPIDU)), ]
  
  for(j in 2:ncol(r2))
  {
    if(r2[i,j] == r2$Max[i])
    {
      #suhii_file_path <- paste0("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\SUHII\\Gam_final\\Raster_", colnames(r2[j]))
      suhii_file_path <- paste0(r2$path[i], colnames(r2[j]))
      suhii_file_path <- paste0(suhii_file_path, "\\")
      suhii_file_path <- paste0(suhii_file_path, r2$X[i])
      suhii_file_path <- paste0(suhii_file_path, ".tif")
      suhii_raster <- raster(suhii_file_path)
      suhii_point <- rasterToPoints(suhii_raster, spatial = TRUE)
      
      AD_rmr_shp<- AD_shp[which(AD_shp$RMRIDU==r2$X_char[i]),]
      AD_rmr_shp_sp <- as(AD_rmr_shp, "Spatial")
      suhii_point_crs <- spTransform(suhii_point, crs(AD_rmr_shp_sp))
      pts.poly <- sp::over(AD_rmr_shp_sp,suhii_point_crs,fn=mean)
      pts.poly2 <- cbind(as.data.frame(as(AD_rmr_shp, "Spatial")@data$ADIDU), pts.poly)
      names(pts.poly2)[names(pts.poly2) == "as(AD_rmr_shp, \"Spatial\")@data$ADIDU"] <- "ADIDU"
      AD_rmr_shp_sp2 <- merge(AD_rmr_shp_sp, pts.poly2)
      
  
      name_file_output <- paste0(r2$X[i], "par_AD")
        rgdal::writeOGR(obj=AD_rmr_shp_sp2, dsn ="D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\SUHII\\Gam_final\\AD_RMR_SUHII", layer =  name_file_output,
                driver = "ESRI Shapefile", overwrite_layer = TRUE) 
      break
    }
  }
}



```

