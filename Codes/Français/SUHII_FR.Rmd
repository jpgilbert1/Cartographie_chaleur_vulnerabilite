---
title: "SUHII"
author: "Departement de géographie - Université Laval"
date: "13/07/2021"
output: html_document
---

```{r eval =FALSE}
library(raster)
library(rgdal)
library(sf)
library(mgcv)
```

#Calcul des SUHII avec le modèle GAM. 
Pour ce faire, le code prend les fichiers d'imperméabilité, de température du sol, du NDVI et du NDBI fait la jointure spatiale entre les données. Un SUHII est créé pour chaque RMR pour chaque province avec l'image de température du sol donnant le meilleur modèle. Les images d'imperméabilité, de NDVI et de NDBI sont préalablement découpées avec les fichiers de RMR dans ArcGIS Pro.

La deuxième boucle s'assure qu'il y a une juxtaposition d'une image de température du sol pour une RMR. S’il y a juxtaposition, le code combine l'image de température du sol, d'imperméabilité, de NDVI et de NDBI. L'image combinée est vérifiée pour s'assurer que l'image n'est pas vide. 

Par la suite, le modèle GAM est appliqué. L'image combinée est transformée en matrice pour pouvoir appliquer adéquatement le modèle GAM. On fait la moyenne des valeurs de température du sol, de NDVI et de NDBI par niveau d'imperméabilité du sol (donc une moyenne pour 1,2,3, ..., 100).

Souvent, il y a plusieurs images de température du sol pour une année et une RMR pour donc je garde que le modèle qui fit le mieux pour modélise les données. Donc, haut dans la boucle, j'ai mis une variable nommée r_carré qui est mise à 0. Puis, si le R2 est plus haut que 0, le code fait la prédiction pour cette image de température du sol. Donc, cela assure que le SUHII est le meilleur pour cette RMR pour l'année regardée. 

En termes de prédiction, le meilleur modèle est pris et les prédictions sont faites à l'aide des données d'imperméabilité du NDVI et du NDBI. Une fois la prédiction faite, le tout est mis dans une matrice et est reclassifié à l'aide du fichier raster d'imperméabilité du sol en remplaçant les valeurs d'imperméabilité par la valeur du SUHII. Le code s'assure que le raster est découpé comme il faut avec le shapefile, puis il exporte le fichier raster.
 
```{r eval = FALSE}
raster_isa <- raster("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\Impermeabilite_des_sols\\QC\\prov_QC_reclass_100_2.tif")
NDVI <- raster("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\NDVI\\QC_2018\\NDVI_2018.tif")
NDBI <- raster("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\NDBI\\QC_2018\\NDBI_2018.tif")
shp <- readOGR("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\Shp_file\\RMR\\RMR_2021\\QC.shp")

filelist <- list.files("D:\\tempo\\Landsat_methode_Wang\\QC_2017\\cut_3", pattern = ".tif", full.names = TRUE)
filelist_court <- list.files("D:\\tempo\\Landsat_methode_Wang\\QC_2017\\cut_3", pattern = ".tif")
shp_RMR <- spTransform(shp,
                       crs(raster_isa))
rm(shp)

for(ii in 1:nrow(shp_RMR))
{

  raster_isa_crop <-crop(raster_isa,extent(shp_RMR[ii,] ))
  raster_isa_crop_mask <- mask(raster_isa_crop, shp_RMR[ii,] )
  rm(raster_isa_crop)
  raster_isa_crop_mask[raster_isa_crop_mask < 0 ] <- NA
  raster_isa_crop_mask[raster_isa_crop_mask > 100 ] <- NA
  raster_isa_crop_mask <- round(raster_isa_crop_mask)
  r_carre <- 0
  for(i in  1:length(filelist))
  {
    print(i)
    tryCatch({
      lst <- raster(filelist[i])
      if(lst@data@max > 2100000000)
      {
        lst = lst/100
        lst[lst == 0] <- NA
      }
      rr_lst <-crop(lst,extent(shp_RMR[ii,] ))
      rr_lst <- mask(rr_lst, shp_RMR[ii,] )
      ex <- extent(raster_isa_crop_mask)
      rr_lst <- crop(rr_lst, ex)
      rm(lst, ex)
        
      isa <- crop(raster_isa_crop_mask, extent(rr_lst))
      r1 <- resample(isa, rr_lst)
      
      isa <- raster(vals=values(r1),ext=extent(rr_lst),crs=crs(rr_lst),
                        nrows=dim(rr_lst)[1],ncols=dim(rr_lst)[2])
      
      rr_NDVI <- crop(NDVI, extent(rr_lst))
      rr_NDVI <- raster(vals=values(rr_NDVI),ext=extent(rr_lst),crs=crs(rr_lst),
                        nrows=dim(rr_lst)[1],ncols=dim(rr_lst)[2])
      
      rr_NDBI <- crop(NDBI, extent(rr_lst))
      rr_NDBI <- raster(vals=values(rr_NDBI),ext=extent(rr_lst),crs=crs(rr_lst),
                        nrows=dim(rr_lst)[1],ncols=dim(rr_lst)[2])
      
      stack_image <- stack(isa,rr_NDVI, rr_NDBI, rr_lst)
      rm(isa, rr_NDVI, rr_NDBI)
      
      v <- data.frame(na.omit(values(stack_image)))
      names(v) <- c('ISA',  'NDVI', 'NDBI','Mean_LST')
      if(nrow(v) != 0)
      {
          v$ISA <- round(v$ISA)
          mean_lst <- aggregate(v, list(v$ISA), mean)
          if(nrow(mean_lst) > 4)
          {
          g <- gam(Mean_LST ~ s(ISA) +NDVI+NDBI,data=mean_lst)
          if(summary(g)$r.sq > r_carre)
          {
            r_carre <- summary(g)$r.sq
            print(summary(g)$r.sq)
            
            #prediction
            pred <- predict(g, mean_lst)
            pred <- data.frame(pred)
            pred$SUHII <- NA
            pred <- cbind(mean_lst, pred)
  
            for(hh in 1:nrow(data.frame(pred)))
            {
             if(hh == 1)
              {
                pred$SUHII[hh] <- 0
              }else
              {
                pred$SUHII[hh] <- pred$pred[hh] - pred$pred[hh-1] +  pred$SUHII[hh-1]
              }
            }
            rclmat <- matrix(pred[,c(2,7)], ncol=2 )
            pred_matrix <- as.matrix(pred[,c(2,7)])
  
            pred_2 <- raster::reclassify(raster_isa_crop_mask,pred_matrix)
            pred_2 [pred_2 < 0 ] <- NA
            pred_2 [pred_2  > 50] <- NA
            plot(pred_2)
            
            nom_fichier_raster <- paste0("D:\\tempo\\Landsat_methode_Wang\\QC_2018\\SUHII2_",shp_RMR@data$RMRIDU[ii]) 
            nom_fichier_raster <- paste0(nom_fichier_raster,"_") 
            nom_fichier_raster <- paste0(nom_fichier_raster, filelist_court[i])
            writeRaster(pred_2 , nom_fichier_raster, 'GTiff', overwrite=TRUE)
            
             nom_fichier <- paste0("D:\\Université Laval\\Cartographie vulnérabilité vagues de chaleur accamblante - Documents\\General\\Data\\SUHII\\Gam_final\\R2_2019\\SUHII_", shp_RMR@data$RMRIDU[ii])
             
              nom_fichier <- paste0(nom_fichier, ".txt")
              
              write.table(r_carre , file = nom_fichier, sep = "\t",
              row.names = TRUE, col.names = NA)
          }
        }
      }
    }, error=function(e){})
  } 
}
```

Finalement, il faut prendre le meilleur modèle selon l'année. Cette section de code fait cela. D'abord, il faut lire le fichier R2. Celui-ci est fait à la main, en prenant les fichiers texte et en mettant la valeur du R2 pour chaque RMR et chaque année. 

Le fichier d'aires de diffusion se retrouve dans le dossier Data

Renomme les colonnes de R2. La première colonne doit être la valeur de la RMRPIDU. Les NA sont mis à 0. Pmax permet d'avoir la valeur maximale pour chaque ligne et la recopie dans la colonne max. Ainsi, l'année qui est == a max est le meilleur modèle à prendre. Le fichier d'aires de diffusion pour le Canada est ensuite lu.

Pour les lignes, va me chercher le fichier RMR. Puis, ne garde que les polygones d'aires de diffusion qui égale le RMRPIDU de la RMR. Ensuite, une boucle sur les colonnes est faite pour déterminer quelle est l'année de la valeur de Pmax. Lorsque c'est le cas, importe le raster SUHII correspondant. Le raster est transformer en point. Ensuite, utilise le fichier d'aires de diffusion découpé selon la RMR. Le fichier d'aires de diffusion est transformé en SpatialPolygon pour effectuer une jointure spatiale. Cela s'effectue avec la fonction 'over'. Elle effectue la moyenne des valeurs de points qui superpose chacune des aires de diffusion. Il ensuite joindre les moyennes au fichier d'aires de diffusion. Donc on doit joindre les deux dataframes. Finalement, exporte le fichier en shapefile.


```{r eval = FALSE}
library(ggplot2)

r2 <- read.table("CHEMIN_OÙ_LE_FICHIER_CONTENANT_LES_VALEURS_DE_R2.csv", sep =";", header = TRUE)

r2$X <- as.character(r2$X)
r2$X[1] <-"001" 
r2$X[2] <-"010"
r2$X[3] <-"011"
r2$X[4] <-"015" 
r2$X_char <- r2$X
r2$X <- paste("SUHII_", r2$X, sep="") 
  
names(r2)[names(r2) == "X2018"] <- "2018"
names(r2)[names(r2) == "X2019"] <- "2019"
names(r2)[names(r2) == "X2020"] <- "2020"

r2[is.na(r2)] <- 0
r2$Max <- pmax(r2$`2018`,r2$`2019`,r2$`2020`)
AD_shp <- sf::st_read("CHEMIN\AD_RMR_SpatialJoin.shp") 

 for (i in 1:nrow(r2))
{
  
  for(j in 2:ncol(r2))
  {
    if(r2[i,j] == r2$Max[i])
    {
      suhii_file_path <- paste0(r2$path[i], colnames(r2[j]))
      suhii_file_path <- paste0(suhii_file_path, "\\")
      suhii_file_path <- paste0(suhii_file_path, r2$X[i])
      suhii_file_path <- paste0(suhii_file_path, ".tif")
      suhii_raster <- raster(suhii_file_path)
      suhii_point <- rasterToPoints(suhii_raster, spatial = TRUE)
      
      AD_rmr_shp<- AD_shp[which(AD_shp$RMRIDU==r2$X_char[i]),]
      AD_rmr_shp_sp <- as(AD_rmr_shp, "Spatial")
      suhii_point_crs <- spTransform(suhii_point, crs(AD_rmr_shp_sp))
      pts.poly <- sp::over(AD_rmr_shp_sp,suhii_point_crs,fn=mean)
      pts.poly2 <- cbind(as.data.frame(as(AD_rmr_shp, "Spatial")@data$ADIDU), pts.poly)
      names(pts.poly2)[names(pts.poly2) == "as(AD_rmr_shp, \"Spatial\")@data$ADIDU"] <- "ADIDU"
      AD_rmr_shp_sp2 <- merge(AD_rmr_shp_sp, pts.poly2)
      
      name_file_output <- paste0(r2$X[i], "par_AD")
      gdal::writeOGR(obj=AD_rmr_shp_sp2, dsn ="CHEMIN_DU_FICHIER", layer =  name_file_output,
                driver = "ESRI Shapefile", overwrite_layer = TRUE) 
      break
    }
  }
}
```

